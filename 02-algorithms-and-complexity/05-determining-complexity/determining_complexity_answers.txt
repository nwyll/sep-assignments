For each -- What's the Big-O of the algorithm? Submit your work and reasoning with your solution.

1. goodbye_world.rb
O(1)
Goodbye_world runs in constant time. Regardless of the value of the input, it takes the same amount of time to print to the screen.

2. find_largest.rb
O(n)
Find_largest runs in linear time. The worst case would be if the largest item was at the end of the collection which would require running through the entire collection 1 by 1 to the last value. Therefore there would be n operations where n is the length of the collection. So as the collection length n grows so does the number of operations at the same rate, n.

3. find_largest_2D_array.rb
O(n^2)
Find_largest for the matrix runs in quadratic time. The worst case again would be if the largest item was at the end of the collection in the last row, last column. And if it is a square matrix. As written, this requires running through n rows of n length 1 by 1 to the last value. So you have n operations iterating through the rows times n operations iterating over the sub array for each row.

4. numbers_recursive.rb
O(2^n)
Recursive Fibonacci runs in exponential time (not good). As written, the function will only return 0 or 1 if n = 0 or 1, respectively. These base cases execute in constant time. Otherwise two recursive calls to numbers(n-2) and numbers(n-1) are made until the previous base cases are reached. The number of recursive calls made grows at a rate of increase matching the Fibonacci sequence itself. And once the recursion reaches the base case, those calls end in the returns executing. For example, for numbers(4) will make 8 total recursive calls, with until we reach 5 base cases, which will add 5 return operations for a total of 13 operations. The chart below summarizes the number of recursive calls made, addition base case returns made and total operations for n > 2. The base cases of n = 0 and n = 1 are ignored since those are best case scenarios.

  n   |  # of recursive calls  | # of base case returns  |  total # of operations
  2   |           2            |            2            |           4
  3   |           4            |            3            |           7
  4   |           8            |            5            |          13
  5   |          14            |            8            |          22
  6   |          24            |           13            |          37
  7   |          40            |           21            |          61

As shown by the data above, for n > 2, the number of recursive calls is increasing at a rate equal to 2 times the Fibonacci sequence itself. The number of base case returns increases at a rate equal to the Fibonacci sequence. These values are added to get the total number of calls 2Fib(n) + Fib(n), should give a rate of increase for the total of 3 times Fib(n), which is what we see in the chart above. The total number of operations does indeed increase a rate 3 times the Fibonacci sequence.

In terms of complexity calculations, coefficients can be factored out since the definition of Big-O is the lower bound k * O(f(n)). So 0(3Fib(n)) = 3 * O(Fib(n)) or just O(Fib(n)). The Fibonacci sequence is tightly bound by f(n) ~ 1.6^n, so we can round up and say the rate of increase will always be less then 2^n, resulting in O(2^n) for a recursive Fibonacci algorithm.

That was fun!!! (No, seriously.)
